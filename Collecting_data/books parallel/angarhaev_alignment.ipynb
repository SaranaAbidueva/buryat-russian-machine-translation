{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e396d469-af84-4d2d-8a5a-6936bd1a065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from razdel import sentenize\n",
    "import docx\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a27c4e-9270-4edc-bd01-75a242b59ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    return '\\n'.join(fullText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0585ecfb-0381-4f6e-8917-83c4f55efbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вытащили текст из docx файлов\n",
    "bur = getText('АнгархаевАЛ_МунхэНогоонХасуури.docx')\n",
    "rus = getText('АнгархаевАЛ_ВечныйЦвет.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e590fc-c3ee-4abb-bccb-321bcd267188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбили на параграфы\n",
    "bur_para = bur.split('\\n')\n",
    "rus_para = rus.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aaafc49-e25f-45bf-b9ef-e26aae7a931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в бурятской книге главы пронумерованы римскими цифрами. Заменяю их на арабские\n",
    "\n",
    "roman = []\n",
    "for i in range(len(bur_para[1:-1])):\n",
    "    if bur_para[i-1] == '' and bur_para[i+1] == '' and bur_para[i] != '' and len(bur_para[i])<10:\n",
    "        roman.append(bur_para[i])\n",
    "\n",
    "i = 0\n",
    "arab = range(1, 41)\n",
    "for j, para in enumerate(bur_para):\n",
    "    if i < 40:\n",
    "        if para == roman[i] :\n",
    "            bur_para[j] = str(arab[i])\n",
    "            i += 1        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f14373-9d7e-48c6-98ef-a62e7c1f9f2b",
   "metadata": {},
   "source": [
    "почему-то в бурятском варианте 40 глав, а в русском переводе 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c7f7370-2046-4a1d-9f8b-1ebf2c9973be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_dict = dict.fromkeys(range(1,47))\n",
    "bur_dict = dict.fromkeys(range(1,41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "899abb0c-43f2-4258-b85f-de64c6f0d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_text = ' '.join(rus_para)\n",
    "ru_chapters = re.split(r'  \\d+  ', ru_text)\n",
    "bur_text = ' '.join(bur_para)\n",
    "bur_chapters = re.split(r'  \\d+  ', bur_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f493b239-6c89-458e-88f4-42df4e98e4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bur_chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79471523-5ae0-4bce-8b2c-fbad24ac03e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ru_chapters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e450fc-e6a2-41e3-b907-f9871d80bb66",
   "metadata": {},
   "source": [
    "# alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa9d9281-6b1b-41d4-b0cd-36d06b8d7d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SaranaAbidueva/labse_bur were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "mname = 'SaranaAbidueva/labse_bur'\n",
    "tokenizer = AutoTokenizer.from_pretrained(mname)\n",
    "model = AutoModel.from_pretrained(mname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cae1942-729d-4bfb-92a2-7a36fa8a5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(book):\n",
    "    # убираем лишние символы\n",
    "    book_text = ' '.join(book)\n",
    "    book_text = book_text.replace('\\xa0', ' ')\n",
    "    book_text = book_text.replace('\\n', '')\n",
    "    book_text = book_text.replace('■', ' ')\n",
    "    book_text = book_text.replace('•', ' ')\n",
    "    book_text = book_text.replace('*', '')\n",
    "    book_text = book_text.replace('|', '')\n",
    "    book_text = book_text.replace('^', '')\n",
    "    book_text = book_text.replace('\\xad', '')\n",
    "    book_text = book_text.replace('Ь', 'h')\n",
    "    book_text = book_text.replace('һ', 'h')\n",
    "    # разделяем на предложения\n",
    "    book_text = sentenize(book_text)\n",
    "    book_text = [sent.text for sent in book_text]\n",
    "    book_text = [x for x in book_text if x != '' and x != ' ' and x != '  ']\n",
    "    return book_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d265c7b4-c4c5-407e-87ea-06bf40e78641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(text):\n",
    "    encoded_input = tokenizer(text, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    with torch.inference_mode():\n",
    "        model_output = model(**encoded_input.to(model.device))\n",
    "    embeddings = model_output.pooler_output\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()\n",
    "\n",
    "def center_norm(v):\n",
    "    v = v - v.mean(0)\n",
    "    return v /  (v**2).sum(1, keepdims=True) ** 0.5\n",
    "\n",
    "\n",
    "def center_dot(x, y):\n",
    "    m = (x.sum(0) + y.sum(0)) / (x.shape[0] + y.shape[0])\n",
    "    x = x - m\n",
    "    y = y - m\n",
    "    x =  x /  (x**2).sum(1, keepdims=True) ** 0.5\n",
    "    y =  y /  (y**2).sum(1, keepdims=True) ** 0.5\n",
    "    return np.dot(x, y.T)\n",
    "def get_top_mean_by_row(x, k=5):\n",
    "    m, n = x.shape\n",
    "    k = min(k, n)\n",
    "    topk_indices = np.argpartition(x, -k, axis=1)[:, -k:]\n",
    "    rows, _ = np.indices((m, k))\n",
    "    return x[rows, topk_indices].mean(1)\n",
    "def align(sims):\n",
    "    \n",
    "    #sims = np.dot(center_norm(orig_vecs), center_norm(sum_vecs).T) ** 3\n",
    "    #sims = center_dot(orig_embeds, sum_embeds) #** 3\n",
    "\n",
    "    rewards = np.zeros_like(sims)\n",
    "    choices = np.zeros_like(sims).astype(int)  # 1: choose this pair, 2: decrease i, 3: decrease j\n",
    "\n",
    "    # алгоритм, разрешающий пропускать сколько угодно пар, лишь бы была монотонность\n",
    "    for i in range(sims.shape[0]):\n",
    "        for j in range(0, sims.shape[1]):\n",
    "            # вариант первый: выровнять i-тое предложение с j-тым\n",
    "            score_add = sims[i, j]\n",
    "            if i > 0 and j > 0:  # вот как тогда выровняются предыдущие \n",
    "                score_add += rewards[i-1, j-1]\n",
    "                choices[i, j] = 1\n",
    "            best = score_add\n",
    "            if i > 0 and rewards[i-1, j] > best:\n",
    "                best = rewards[i-1, j]\n",
    "                choices[i, j] = 2\n",
    "            if j > 0 and rewards[i, j-1] > best:\n",
    "                best = rewards[i, j-1]\n",
    "                choices[i, j] = 3\n",
    "            rewards[i, j] = best\n",
    "    alignment = []\n",
    "    i = sims.shape[0] - 1\n",
    "    j = sims.shape[1] - 1\n",
    "    while i > 0 and j > 0:\n",
    "        if choices[i, j] == 1:\n",
    "            alignment.append([i, j])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif choices[i, j] == 2:\n",
    "            i -= 1\n",
    "        else:\n",
    "            j -= 1\n",
    "    return alignment[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c639c63-1448-4c06-af8e-1d1c9ee728fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ru_chapters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# посмотрела кол-во предложений в каждой главе, надеялась, что будут совпадения\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chapter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mru_chapters\u001b[49m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m40\u001b[39m:\n\u001b[0;32m      4\u001b[0m         sents_bxr \u001b[38;5;241m=\u001b[39m [s\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sentenize(bur_chapters[i])]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ru_chapters' is not defined"
     ]
    }
   ],
   "source": [
    "# посмотрела кол-во предложений в каждой главе, надеялась, что будут совпадения\n",
    "for i, chapter in enumerate(ru_chapters):\n",
    "    if i < 40:\n",
    "        sents_bxr = [s.text for s in sentenize(bur_chapters[i])]\n",
    "        sents_ru = [s.text for s in sentenize(ru_chapters[i])]\n",
    "        print(i, ' ', len(sents_bxr), ' ', len(sents_ru))\n",
    "    else:\n",
    "        sents_ru = [s.text for s in sentenize(ru_chapters[i])]\n",
    "        print(i, ' ', len(sents_ru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93aa33-112d-4ccb-aeff-063464bdd980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "for i, chapter in enumerate(tqdm(ru_chapters)):\n",
    "    sents_ru = clean_text(chapter)\n",
    "    sents_bxr = clean_text(bur_chapters[i] + bur_chapters[i+1])\n",
    "    print(0)\n",
    "    emb_ru = np.stack([embed(s) for s in sents_ru])\n",
    "    emb_er = np.stack([embed(s) for s in sents_bxr])\n",
    "    print(0.5)\n",
    "    pen = np.array([[min(len(x), len(y)) / max(len(x), len(y)) for x in sents_bxr] for y in sents_ru])\n",
    "    sims = np.maximum(0, np.dot(emb_ru, emb_er.T)) ** 1 * pen\n",
    "    print(1)\n",
    "    alpha = 0.2\n",
    "    penalty = 0.2\n",
    "    sims_rel = (sims.T - get_top_mean_by_row(sims) * alpha).T - get_top_mean_by_row(sims.T) * alpha - penalty\n",
    "\n",
    "    alignment = align3(sims_rel)\n",
    "\n",
    "    total_score = sum(sims[i, j] for i, j in alignment) / min(sims.shape)\n",
    "    if total_score < 0.15:\n",
    "        continue\n",
    "    \n",
    "    for i, j in alignment:\n",
    "        if sims[i, j] >= 0.50: # порог высоковат; часть предложений мы потеряем, но полученные зато будут чистыми\n",
    "            pairs.append([sents_bxr[j], sents_ru[i]])\n",
    "    tq.set_description(str(len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e6991-6b74-4d56-bbbe-c22e901444db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
